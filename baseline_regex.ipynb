{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RulesAspectClassifier:\n",
    "\n",
    "    perf_suf_tmpl = re.compile(\"^(po|pro|na|iz|za|s|u|do|raz|od)\")\n",
    "    imp_suf_tmpl  = re.compile(\"(iva|ava|ova|uva)$\")\n",
    "\n",
    "    def __init__(self, biase:str=\"imp\"):\n",
    "        self.biase = biase\n",
    "\n",
    "    def predict_(self, x: str) -> int:\n",
    "\n",
    "        x = x.lower()\n",
    "\n",
    "        if self.perf_suf_tmpl.match(x):\n",
    "            return \"perf\"\n",
    "\n",
    "        elif self.imp_suf_tmpl.search(x):\n",
    "            return \"imp\"\n",
    "\n",
    "        elif x.endswith(\"ti\"):\n",
    "            return \"imp\"\n",
    "\n",
    "        ##  Если ничего не найдено, возвращаем предубеждение\n",
    "        else:\n",
    "            return self.biase\n",
    "\n",
    "    def predict(self, X:list[str]) -> list[str]:\n",
    "        return [\n",
    "            self.predict_(x)\n",
    "            for x\n",
    "            in X\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path.cwd() / \"data\" / \"forms2sents.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>aspect</th>\n",
       "      <th>disambig</th>\n",
       "      <th>db_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacati</td>\n",
       "      <td>baca</td>\n",
       "      <td>imp</td>\n",
       "      <td>imp</td>\n",
       "      <td>set-s2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacati</td>\n",
       "      <td>bacaju</td>\n",
       "      <td>imp</td>\n",
       "      <td>imp</td>\n",
       "      <td>set-s693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lemma    word aspect disambig      db_id\n",
       "0  bacati    baca    imp      imp  set-s2762\n",
       "1  bacati  bacaju    imp      imp   set-s693"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path, sep=\"\\t\", index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"word\"]\n",
    "y = df[\"aspect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_model_imp_biase  = RulesAspectClassifier(biase=\"imp\")\n",
    "rules_model_perf_biase = RulesAspectClassifier(biase=\"perf\")\n",
    "rules_model_both_biase = RulesAspectClassifier(biase=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_imp_pred  = rules_model_imp_biase.predict(X)\n",
    "y_perf_pred = rules_model_perf_biase.predict(X)\n",
    "y_both_pred = rules_model_both_biase.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       0.00      0.00      0.00       212\n",
      "         imp       0.60      0.66      0.63      2315\n",
      "        perf       0.66      0.66      0.66      2432\n",
      "\n",
      "    accuracy                           0.63      4959\n",
      "   macro avg       0.42      0.44      0.43      4959\n",
      "weighted avg       0.60      0.63      0.62      4959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_imp_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       0.00      0.00      0.00       212\n",
      "         imp       0.56      0.05      0.09      2315\n",
      "        perf       0.49      0.97      0.65      2432\n",
      "\n",
      "    accuracy                           0.50      4959\n",
      "   macro avg       0.35      0.34      0.25      4959\n",
      "weighted avg       0.50      0.50      0.36      4959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_perf_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both       0.08      0.89      0.15       212\n",
      "         imp       0.56      0.05      0.09      2315\n",
      "        perf       0.66      0.66      0.66      2432\n",
      "\n",
      "    accuracy                           0.38      4959\n",
      "   macro avg       0.43      0.53      0.30      4959\n",
      "weighted avg       0.59      0.38      0.37      4959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_both_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
